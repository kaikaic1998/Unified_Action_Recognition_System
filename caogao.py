from collections import deque
import numpy as np
import threading
import multiprocessing
import time
from queue import Queue # generally slower than list for iteration
# because it includes additional overhead for managing thread safety and synchronization, which is not present in a regular list
from collections import deque
import pathlib
import random
from matplotlib import pyplot as plt
from torchvision import datasets

def try_deque():
    deq = deque([1, 2])

    for i in range(3):
        deq.append(i)

    print(len(deq))

    for element in deq:
        print(element)
    deq = np.array(deq)
    print(deq.shape)
# try_deque()

def queue_vs_list():
    start_time = time.time()
    q = Queue(maxsize = 99999)
    for i in range(99999):
        q.put(i)

    for i in q.queue:
        continue
    end_time = time.time()
    execution_time = end_time - start_time
    print('time spent: ', round(execution_time, 4))

    start_time = time.time()
    lst = []
    for i in range(99999):
        lst.append(99999)

    for i in lst:
        continue
    end_time = time.time()
    execution_time = end_time - start_time
    print('time spent: ', round(execution_time, 4))
# queue_vs_list()

# def print_cube(num):
#     # function to print cube of given num
#     for i in range(999999999):
#         continue
#     print("Cube: {}" .format(num * num * num))
 
# def print_square(num):
#     # function to print square of given num
#     for i in range(999999999):
#         continue
#     print("Square: {}" .format(num * num))

# def run_with_thread():
#     # creating thread
#     t1 = threading.Thread(target=print_square, args=(10,))
#     t2 = threading.Thread(target=print_cube, args=(10,))

#     # starting thread 1
#     t1.start()
#     # starting thread 2
#     t2.start()

#     # wait until thread 1 is completely executed
#     t1.join()
#     # wait until thread 2 is completely executed
#     t2.join()

# def run_with_multiprocess():
#     t1 = multiprocessing.Process(target=print_square, args=(10,))
#     t2 = multiprocessing.Process(target=print_cube, args=(10,))

#     t1.start()
#     t2.start()

#     t1.join()
#     t2.join()

# def run_without_thread():
#     print_cube(10)
#     print_square(10)

# if __name__ == "__main__":
#     start_time = time.time()

#     # run_with_thread() # 20.9 s
#     # run_without_thread() # 21.55 s
#     run_with_multiprocess() # 11.0284

#     end_time = time.time()
#     execution_time = end_time - start_time
#     print('time spent: ', round(execution_time, 4))

import torch
import torch.nn as nn

# # Correct way to use CrossEntropyLoss
# loss = nn.CrossEntropyLoss()
# input = torch.randn(1, 5)
# target = torch.empty(1, dtype=torch.long).random_(5)
# output = loss(input, target)

# print(input)
# print(target)
# print(output)
# print('\n')

# input = torch.randn(3, 5, requires_grad=True)
# target = torch.tensor([1, 0, 4])
# output = nn.functional.nll_loss(nn.functional.log_softmax(input, dim=1), target)
# print(input)
# print(target)
# print(output)

# m = nn.LogSoftmax(dim=1)
# loss = nn.NLLLoss()
# # input is of size N x C = 3 x 5
# input = torch.randn(1, 5, requires_grad=True)
# # each element in target has to have 0 <= value < C
# # target = torch.tensor([1, 0, 4])
# target = torch.empty(1, dtype=torch.long).random_(5)
# softmax = m(input)
# output = loss(softmax, target)

# print(input)
# print(softmax)
# print(target)
# print(output, '\n')

# softmax = torch.tensor([0.006354291, 0.028920725, 1.0, 0.00805, 0.00046146192], requires_grad=True)
# input = torch.log(softmax)
# target = torch.tensor(2, dtype=torch.long)
# output = loss(input, target)

# print(softmax)
# print(input)
# print(target)
# print(output)

# random_index = list(range(5))
# for i in range(5):
#     random.shuffle(random_index)
#     print('random numbers', random_index)


lst = [0.5990503430366516, 1.0268157720565796, 1.2245938777923584, 0.47651344537734985, 0.06275073438882828, 2.0258328914642334, 1.564809799194336, 0.26489439606666565, 0.17107366025447845, 0.5253225564956665, 0.0657099038362503, 0.00022575691400561482, 0.00033802041434682906, 0.0003496989083942026, 0.00011932138295378536, 0.00012182447244413197, 0.27573537826538086, 2.346694231033325, 0.5286085605621338, 2.264974000354414e-06, 1.2426667213439941, 0.0011202972382307053, 1.6689160474925302e-05, 0.0001629458274692297, 7.747180938720703, 1.7086035013198853, 2.565197229385376, 2.3841855067985307e-07, 0.03950880095362663, 0.004015597980469465, 0.18399032950401306, 8.344646857949556e-07, 9.536738616588991e-07, 1.1920928244535389e-07, 2.3841855067985307e-07, 0.03378938138484955, 0.1618020236492157, 0.0, 0.028205817565321922, 0.0, 0.0, 4.127318859100342, 1.6244487762451172, 0.04640490561723709, 
2.3841855067985307e-07, 5.245195097813848e-06, 2.2291887944447808e-05, 1.1920928244535389e-07, 1.1444026313256472e-05, 7.152555099310121e-07, 0.0, 0.013806086033582687, 2.3841855067985307e-07, 0.0, 0.0, 7.92710343375802e-05, 0.0005715643637813628, 0.0, 3.015949550899677e-05, 0.0, 1.9997241497039795, 0.042637284845113754, 0.0012774649076163769, 0.0, 0.015349473804235458, 2.622600959512056e-06, 1.549708758830093e-05, 1.5497195136049413e-06, 1.1920928244535389e-07, 0.0002094287920044735, 1.1920928244535389e-07, 3.158996332786046e-05, 0.0, 2.145764938177308e-06, 1.5497195136049413e-06, 1.1920928244535389e-07, 2.1219027985353023e-05, 4.768370445162873e-07, 0.0, 0.0, 1.6331539882230572e-05, 2.253030106658116e-05, 3.576278118089249e-07, 1.5020257706055418e-05, 0.0, 1.1920928244535389e-07, 3.4570634852570947e-06, 0.0, 2.3841855067985307e-07, 0.0, 4.0531076592742465e-06, 0.0, 4.0531076592742465e-06, 0.0, 9.298280929215252e-06, 2.3841855067985307e-07, 1.1920928244535389e-07, 0.0, 0.0, 3.2186455882765586e-06, 1.1920928244535389e-07, 0.0005510718910954893, 0.0, 2.50339189733495e-06, 0.0, 1.6689286894688848e-06, 5.1377883210079744e-05, 3.576278118089249e-07, 0.0008831891464069486, 1.8954096958623268e-05, 0.0, 0.0, 0.0, 0.0, 7.152555099310121e-07, 5.8412379075889476e-06, 0.0, 4.95898348162882e-05, 5.483612312673358e-06, 5.960462772236497e-07, 8.4638240878121e-06, 1.1920928244535389e-07, 1.5497195136049413e-06, 0.0, 3.099436753473128e-06, 0.0, 0.0, 1.5497195136049413e-06, 6.198863957251888e-06, 1.0132738680113107e-05, 0.0, 1.311301275563892e-06, 9.691245941212401e-05, 0.0, 8.4638240878121e-06, 1.1920922133867862e-06, 0.0, 2.9444261599564925e-05, 1.0728830375228426e-06, 0.0, 9.536738616588991e-07, 8.940656698541716e-06, 0.00040260792593471706, 2.7418097943154862e-06, 5.245195097813848e-06, 0.0, 0.0, 0.0, 3.099436753473128e-06, 3.933898824470816e-06, 1.1920928244535389e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1920928244535389e-07, 0.0, 2.264974000354414e-06, 0.0, 9.536738616588991e-07, 1.9073468138230965e-06, 6.318072337307967e-06, 0.0, 0.0, 0.0006073060794733465, 1.1920928244535389e-07, 2.7418097943154862e-06, 0.0, 0.0, 6.198863957251888e-06, 3.6954195820726454e-05, 0.0, 8.344646857949556e-07, 2.3841855067985307e-07, 4.887569048150908e-06, 0.0, 
0.0, 0.0007002285565249622, 0.0, 2.5510462364763953e-05, 0.0, 1.1920928244535389e-07, 0.0, 9.059865078597795e-06, 4.6491513785440475e-06, 5.960462772236497e-07, 8.344646857949556e-07, 0.0, 0.0, 0.0, 2.3841830625315197e-06, 0.0, 0.0, 0.0, 6.079655122448457e-06, 4.768370445162873e-07, 0.0009690594743005931, 0.0, 7.510157047363464e-06, 0.0, 5.245195097813848e-06, 2.3841830625315197e-06, 1.1920928244535389e-07, 8.344646857949556e-07, 0.0, 1.0967194612021558e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 6.472854875028133e-05, 0.0, 2.0265558760002023e-06, 5.960462772236497e-07, 3.933898824470816e-06, 2.95634672511369e-05, 1.1920928244535389e-07, 0.0, 0.0, 0.0, 0.0005439232336357236, 1.1920928244535389e-07, 0.0, 5.960462772236497e-07, 0.0, 0.0, 0.0, 2.7418097943154862e-06, 1.1920928244535389e-07, 1.1920928244535389e-07, 0.0, 9.775113539944869e-06, 2.3841855067985307e-07, 9.894321920000948e-06, 1.1920928244535389e-07, 0.0, 7.152555099310121e-07, 2.0265558760002023e-06, 0.0, 5.173549288883805e-05, 0.0, 6.41325386823155e-05, 5.960462772236497e-07, 0.00010132275929208845, 0.0, 0.0, 0.0, 9.536738616588991e-07, 1.1920922133867862e-06, 2.3841855067985307e-07, 0.0, 2.002696055569686e-05, 2.145764938177308e-06, 3.4570634852570947e-06, 2.145764938177308e-06, 2.145764938177308e-06, 0.0018176001030951738, 0.0, 6.198863957251888e-06, 0.0, 5.722029527532868e-06, 0.0, 0.0, 1.1920928244535389e-07, 0.0, 1.6689286894688848e-06, 5.8412379075889476e-06, 0.0006386386230587959, 0.0, 0.0, 0.0, 1.1920928244535389e-07, 0.0, 1.1920928244535389e-07, 3.4570634852570947e-06, 1.1920928244535389e-07, 1.1920928244535389e-07, 0.0, 0.0, 0.0, 0.0, 1.1920928244535389e-07, 2.13382354559144e-05, 0.0, 0.0, 5.483612312673358e-06, 8.344646857949556e-07, 0.0, 0.00011955977242905647, 0.0, 0.0, 7.152555099310121e-07, 0.0, 3.576272320060525e-06, 1.1920928244535389e-07, 3.886147169396281e-05, 1.6689286894688848e-06, 1.0728830375228426e-06, 1.0013530300057027e-05, 2.5510462364763953e-05, 0.0009160612826235592, 0.0, 6.198863957251888e-06, 9.775113539944869e-06, 2.861018856492592e-06, 7.510157047363464e-06, 1.0013530300057027e-05, 2.264974000354414e-06, 0.0, 0.0, 0.0, 0.0, 2.145764938177308e-06, 0.0, 0.0, 7.915183232398704e-05, 4.291525328881107e-06, 0.0, 5.960446742392378e-06, 0.0, 4.768370445162873e-07, 3.576278118089249e-07, 2.3841855067985307e-07, 3.576278118089249e-07, 1.1920928244535389e-07, 4.887569048150908e-06, 4.768370445162873e-07, 7.390948667307384e-06, 8.344646857949556e-07, 0.0, 0.0, 1.5497195136049413e-06, 0.0008148210472427309, 9.775113539944869e-06, 0.0, 0.0, 2.861018856492592e-06, 0.0, 0.0, 0.0, 0.0, 0.0005346299149096012, 0.0, 1.5258672647178173e-05, 1.1920928244535389e-07, 9.65590606938349e-06, 1.1920928244535389e-07, 3.3378546504536644e-06, 7.629365427419543e-06, 1.4305104514278355e-06, 0.0, 0.0, 9.536738616588991e-07, 3.4570634852570947e-06, 5.8412379075889476e-06, 0.0, 0.0006804534932598472, 3.576278118089249e-07, 2.407998726994265e-05, 9.775113539944869e-06, 8.344646857949556e-07, 0.0, 0.0, 6.079655122448457e-06, 0.0, 0.0, 0.0, 1.4305104514278355e-06, 2.264974000354414e-06, 0.001053374377079308, 2.3841830625315197e-06, 0.0, 4.768370445162873e-07, 0.0, 0.0, 2.3841855067985307e-07, 6.592056161025539e-05, 0.0, 1.1920928244535389e-07, 1.1920928244535389e-07, 1.1920928244535389e-07, 1.1920928244535389e-07, 1.4305104514278355e-06, 0.0, 5.8412379075889476e-06, 7.510157047363464e-06, 0.0, 1.6689286894688848e-06, 8.106198947643861e-06, 0.0, 0.0, 0.0, 2.90866428258596e-05, 0.0, 2.3841855067985307e-07, 1.4305104514278355e-06, 4.768370445162873e-07, 5.1973900554003194e-05, 0.0, 4.0531076592742465e-06, 0.0, 0.0, 3.576278118089249e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.198863957251888e-06, 0.0, 0.0, 1.1920922133867862e-06, 1.4662635294371285e-05, 0.0, 1.0728830375228426e-06, 4.172316494077677e-06, 2.50339189733495e-06, 2.9802276912960224e-06, 1.7881377516459906e-06, 0.0, 0.0, 7.748573807475623e-06, 5.936446541454643e-05, 3.814689989667386e-06, 0.0, 0.0, 0.00047469791024923325, 0.0, 2.145764938177308e-06, 0.0007952864980325103, 0.0, 2.3841855067985307e-07, 8.22540732769994e-06, 2.3841855067985307e-07, 2.706014311115723e-05, 8.344646857949556e-07]
# Plot the list data
plt.plot(lst)

# Show the plot
plt.show()